{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774ab8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Dataset: thermoproteota_data.csv ---\n",
      "Stage 1: Quantifying Low-Complexity Regions (SEG: W=12, T=2.2, E=2.5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229906/229906 [02:37<00:00, 1459.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Flagged/Excluded 29109 sequences with >20% low-complexity content.\n",
      "Stage 2: Calculating Biophysical Properties...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200797/200797 [00:12<00:00, 15693.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3: Grouping by Organism Id and Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Organisms: 100%|██████████| 98/98 [00:00<00:00, 1315.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Complete ---\n",
      "Organisms Passed: 0 out of 98\n",
      "Validated Data: thermoproteota_validated_data.csv\n",
      "Metadata: thermoproteota_validated_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "# --- CONFIGURATION BASED ON TEXT ---\n",
    "# Section 3.2.2: Low-Complexity Region Quantification\n",
    "SEG_WINDOW = 12\n",
    "SEG_TRIGGER = 2.2\n",
    "SEG_EXTENSION = 2.5\n",
    "LOW_COMPLEXITY_MAX_FRACTION = 0.20  # >20% exclusion threshold\n",
    "\n",
    "# Section 3.2.2: Physicochemical Validation\n",
    "HALO_MEDIAN_PI_MIN = 4.2\n",
    "HALO_MEDIAN_PI_MAX = 4.8\n",
    "KS_ALPHA = 0.01  # Significance level\n",
    "\n",
    "# Amino Acid Composition thresholds (Halobacteria)\n",
    "HALO_DE_PCT_MIN = 20.0     # Asp+Glu > 20%\n",
    "HALO_K_PCT_MAX = 2.0       # Lys < 2%\n",
    "HALO_DE_K_RATIO_MIN = 10.0 # (Asp+Glu)/Lys > 10\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def calculate_shannon_entropy(sequence):\n",
    "    \"\"\"Calculates Shannon entropy in bits for a sequence string.\"\"\"\n",
    "    L = len(sequence)\n",
    "    if L == 0: return 0\n",
    "    counts = Counter(sequence)\n",
    "    entropy = 0\n",
    "    for count in counts.values():\n",
    "        p = count / L\n",
    "        entropy -= p * math.log2(p)\n",
    "    return entropy\n",
    "\n",
    "def seg_low_complexity_filter(sequence, window=12, trigger=2.2, extension=2.5):\n",
    "    \"\"\"\n",
    "    Implements the SEG algorithm logic:\n",
    "    1. Identification: Sliding window entropy < trigger.\n",
    "    2. Extension: Merges overlapping/adjacent windows if entropy remains low (< extension).\n",
    "    Returns the fraction of the sequence covered by low-complexity regions.\n",
    "    \"\"\"\n",
    "    N = len(sequence)\n",
    "    if N < window:\n",
    "        return 0.0\n",
    "    \n",
    "    # 1. Identify \"Raw\" Low Complexity Segments\n",
    "    is_lc = np.zeros(N, dtype=bool)\n",
    "    \n",
    "    # We first find all windows that trigger the low complexity state\n",
    "    trigger_indices = []\n",
    "    for i in range(N - window + 1):\n",
    "        subseq = sequence[i : i+window]\n",
    "        H = calculate_shannon_entropy(subseq)\n",
    "        if H < trigger:\n",
    "            trigger_indices.append(i)\n",
    "            # Mark the window itself\n",
    "            is_lc[i : i+window] = True\n",
    "            \n",
    "    # 2. Extension Phase (Simplistic implementation of SEG extension)\n",
    "    # If a window is \"triggered\", we check if we can extend it left/right \n",
    "    # while keeping entropy below the 'extension' threshold.\n",
    "    # Note: True SEG optimization is complex; this approximates the 'extension' param\n",
    "    # by allowing the merge of regions if the combined entropy is low.\n",
    "    \n",
    "    # A simplified interpretation for pipeline purposes:\n",
    "    # If we are in a low complexity state, we are more tolerant (extension threshold)\n",
    "    # regarding what we consider \"still low complexity\" nearby.\n",
    "    \n",
    "    # For this pipeline, we will refine the mask:\n",
    "    # Any block marked 'True' is a seed. We check adjacent windows against 'extension'.\n",
    "    # (Since standard SEG code is C/C++, this python approximation ensures we catch the regions).\n",
    "    \n",
    "    # Re-scan to extend seeds using the higher 'extension' entropy threshold\n",
    "    final_lc_mask = is_lc.copy()\n",
    "    \n",
    "    # Identify continuous blocks\n",
    "    # (In a full SEG implementation, this involves iterative extension. \n",
    "    # Here, we ensure that if we are \"near\" a trigger, we use the extension threshold).\n",
    "    \n",
    "    # Refined pass: Check all windows again against EXTENSION threshold\n",
    "    # But only apply if they overlap/touch an existing TRIGGERED region.\n",
    "    \n",
    "    # Actually, a safer Pythonic approximation for \"Extension\" in this context\n",
    "    # is often interpreted as: \"Once triggered, the condition to STAY in low-complexity\n",
    "    # is the extension value.\"\n",
    "    \n",
    "    # Let's perform a second pass to bridge gaps using the extension threshold\n",
    "    for i in range(N - window + 1):\n",
    "        if is_lc[i:i+window].any(): # If it touches a triggered region\n",
    "            subseq = sequence[i : i+window]\n",
    "            H = calculate_shannon_entropy(subseq)\n",
    "            if H < extension: # Higher threshold (easier to pass)\n",
    "                final_lc_mask[i : i+window] = True\n",
    "\n",
    "    return np.sum(final_lc_mask) / N\n",
    "\n",
    "def get_biophysical_stats(sequence):\n",
    "    \"\"\"Returns pI and Amino Acid percentages.\"\"\"\n",
    "    try:\n",
    "        # Standardize\n",
    "        clean_seq = sequence.upper().replace('X', '').replace('B', '').replace('Z', '').replace('J', '')\n",
    "        if not clean_seq: return None\n",
    "        \n",
    "        X = ProteinAnalysis(clean_seq)\n",
    "        pI = X.isoelectric_point()\n",
    "        \n",
    "        # AA Composition\n",
    "        aa_counts = X.count_amino_acids()\n",
    "        total_len = len(clean_seq)\n",
    "        if total_len == 0: return None\n",
    "        \n",
    "        D = aa_counts.get('D', 0)\n",
    "        E = aa_counts.get('E', 0)\n",
    "        K = aa_counts.get('K', 0)\n",
    "        \n",
    "        pct_DE = ((D + E) / total_len) * 100.0\n",
    "        pct_K = (K / total_len) * 100.0\n",
    "        \n",
    "        ratio_DE_K = (D + E) / K if K > 0 else (D + E) # Handle divide by zero\n",
    "        \n",
    "        return pI, pct_DE, pct_K, ratio_DE_K\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# --- MAIN PIPELINE ---\n",
    "\n",
    "def validation_pipeline(input_csv, output_data, output_metadata):\n",
    "    print(f\"--- Loading Dataset: {input_csv} ---\")\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Enable tqdm for pandas apply operations\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    # --- 1. Low-Complexity Region Quantification ---\n",
    "    print(f\"Stage 1: Quantifying Low-Complexity Regions (SEG: W={SEG_WINDOW}, T={SEG_TRIGGER}, E={SEG_EXTENSION})...\")\n",
    "    \n",
    "    # Apply the SEG filter logic with progress bar\n",
    "    df['lc_fraction'] = df['Sequence'].progress_apply(lambda x: seg_low_complexity_filter(x, SEG_WINDOW, SEG_TRIGGER, SEG_EXTENSION))\n",
    "    \n",
    "    # Flag/Exclude > 20%\n",
    "    initial_count = len(df)\n",
    "    df_clean = df[df['lc_fraction'] <= LOW_COMPLEXITY_MAX_FRACTION].copy()\n",
    "    dropped_count = initial_count - len(df_clean)\n",
    "    if dropped_count > 0:\n",
    "        print(f\"  -> Flagged/Excluded {dropped_count} sequences with >20% low-complexity content.\")\n",
    "    \n",
    "    # --- 2. Calculate Biophysical Properties ---\n",
    "    print(\"Stage 2: Calculating Biophysical Properties...\")\n",
    "    # This returns a dataframe of stats with progress bar\n",
    "    stats_data = df_clean['Sequence'].progress_apply(lambda x: pd.Series(get_biophysical_stats(x)))\n",
    "    stats_data.columns = ['pI', 'pct_DE', 'pct_K', 'ratio_DE_K']\n",
    "    \n",
    "    # Merge back\n",
    "    df_clean = pd.concat([df_clean, stats_data], axis=1)\n",
    "    df_clean = df_clean.dropna(subset=['pI']) # Drop failures\n",
    "\n",
    "    # --- 3. Grouping and Physicochemical Validation ---\n",
    "    print(\"Stage 3: Grouping by Organism Id and Validating...\")\n",
    "    grouped = df_clean.groupby(['Organism Id', 'Proteome Id'])\n",
    "    \n",
    "    valid_organism_ids = []\n",
    "    metadata_records = []\n",
    "\n",
    "    # Wrap grouped iterator with tqdm for progress bar\n",
    "    for (org_id, prot_id), group in tqdm(grouped, total=len(grouped), desc=\"Validating Organisms\"):\n",
    "        pi_values = group['pI'].values\n",
    "        \n",
    "        # --- A. Isoelectric Point Distribution ---\n",
    "        # 1. Median Check (Strict ~4.2 - 4.8)\n",
    "        median_pi = np.median(pi_values)\n",
    "        is_median_valid = (HALO_MEDIAN_PI_MIN <= median_pi <= HALO_MEDIAN_PI_MAX)\n",
    "        \n",
    "        # 2. KS Test\n",
    "        # Text: \"Distribution comparisons via Kolmogorov–Smirnov test (alpha=0.01) will verify significant shifts.\"\n",
    "        # We compare against the Halophilic reference (Normal dist, mean=4.5, std=1.0)\n",
    "        # Note on KS Test interpretation:\n",
    "        # Null Hypothesis (H0): The sample comes from the reference distribution.\n",
    "        # If p-value < alpha, we REJECT H0 (It is NOT the reference distribution).\n",
    "        # Therefore, we WANT p-value > alpha (we want it to look like the reference).\n",
    "        ks_stat, ks_pvalue = stats.kstest(pi_values, 'norm', args=(4.5, 1.0))\n",
    "        \n",
    "        # If p > 0.01, we cannot reject that it is Halophilic (Pass).\n",
    "        # If p < 0.01, it is significantly different from Halophilic profile (Fail).\n",
    "        is_ks_valid = ks_pvalue > KS_ALPHA\n",
    "        \n",
    "        # --- B. Amino Acid Composition Profiles ---\n",
    "        # \"Asp+Glu > 20%, Lys < 2%, Ratio > 10\"\n",
    "        avg_pct_DE = group['pct_DE'].mean()\n",
    "        avg_pct_K = group['pct_K'].mean()\n",
    "        avg_ratio = group['ratio_DE_K'].mean()\n",
    "        \n",
    "        is_comp_valid = (\n",
    "            (avg_pct_DE >= HALO_DE_PCT_MIN) and\n",
    "            (avg_pct_K <= HALO_K_PCT_MAX) and\n",
    "            (avg_ratio >= HALO_DE_K_RATIO_MIN)\n",
    "        )\n",
    "\n",
    "        # --- FINAL DECISION ---\n",
    "        # The organism must pass the Median pI check AND the KS distribution check.\n",
    "        # Composition checks reinforce the signature.\n",
    "        \n",
    "        # Strict adherence to \"verify significant shifts\":\n",
    "        # We enforce Median pI range and KS distribution fit.\n",
    "        final_valid = is_median_valid and is_ks_valid and is_comp_valid\n",
    "\n",
    "        if final_valid:\n",
    "            valid_organism_ids.append(org_id)\n",
    "            \n",
    "        metadata_records.append({\n",
    "            'Proteome Id': prot_id,\n",
    "            'Organism Id': org_id,\n",
    "            'Sequence Count': len(group),\n",
    "            'Median pI': round(median_pi, 4),\n",
    "            'KS Statistic': round(ks_stat, 4),\n",
    "            'KS P-Value': round(ks_pvalue, 6),\n",
    "            'Avg Asp+Glu%': round(avg_pct_DE, 2),\n",
    "            'Avg Lys%': round(avg_pct_K, 2),\n",
    "            'DE/K Ratio': round(avg_ratio, 2),\n",
    "            'Validation Status': 'Passed' if final_valid else 'Failed'\n",
    "        })\n",
    "\n",
    "    # --- 4. Save Results ---\n",
    "    # Filter Original Data\n",
    "    final_df = df_clean[df_clean['Organism Id'].isin(valid_organism_ids)].copy()\n",
    "    output_cols = ['Proteome Id', 'Organism Id', 'Entry', 'Sequence']\n",
    "    final_df = final_df[output_cols]\n",
    "    \n",
    "    final_df.to_csv(output_data, index=False)\n",
    "    \n",
    "    # Save Metadata\n",
    "    meta_df = pd.DataFrame(metadata_records)\n",
    "    meta_df.to_csv(output_metadata, index=False)\n",
    "    \n",
    "    print(f\"--- Processing Complete ---\")\n",
    "    print(f\"Organisms Passed: {len(valid_organism_ids)} out of {len(grouped)}\")\n",
    "    print(f\"Validated Data: {output_data}\")\n",
    "    print(f\"Metadata: {output_metadata}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validation_pipeline(\n",
    "        'thermoproteota_data.csv', \n",
    "        'thermoproteota_validated_data.csv', \n",
    "        'thermoproteota_validated_metadata.csv'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
