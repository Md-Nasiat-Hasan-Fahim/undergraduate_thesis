{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc864606",
   "metadata": {},
   "source": [
    "# Halobacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8c0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[START] Collecting salt_extreme_halobacteria...\n",
      "Query: (taxonomy_id:183963) AND (fragment:false) AND (length:[100 TO 800]) AND NOT (keyword:methanogen) AND (reviewed:true)\n",
      "\n",
      "[DONE] Saved 1872 rows to salt_extreme_halobacteria.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. User Identification (REQUIRED by UniProt to avoid 403 Errors)\n",
    "# Please replace with your actual email so UniProt can contact you if the script causes issues.\n",
    "CONTACT_EMAIL = \"uusshas12@gmail.com\"\n",
    "\n",
    "# 2. Define Datasets & Queries\n",
    "# Limits removed to collect ALL available data as requested.\n",
    "datasets = {\n",
    "    # \"thermoproteota\": {\n",
    "    #     \"query\": \"(taxonomy_id:28889) AND (fragment:false) AND (length:[100 TO 800])\",\n",
    "    #     \"limit\": None    # Download all (~222k)\n",
    "    # },\n",
    "    \"salt_extreme_halobacteria\": {\n",
    "        \"query\": \"(taxonomy_id:183963) AND (fragment:false) AND (length:[100 TO 800]) AND NOT (keyword:methanogen) AND (reviewed:true)\",\n",
    "        \"limit\": None    # Download all (~1M)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Define Columns (Mapped to UniProt API Fields)\n",
    "fields = [\n",
    "    \"id\",                       # Entry Name\n",
    "    \"gene_names\",               # Gene Names\n",
    "    \"organism_name\",            # Organism\n",
    "    \"organism_id\",              # Organism (ID)\n",
    "    \"protein_name\",             # Protein names\n",
    "    \"xref_proteomes\",           # Proteomes (Group by this later)\n",
    "    \"fragment\",                 # Fragment\n",
    "    \"length\",                   # Length\n",
    "    \"sequence\",                 # Sequence\n",
    "    \"absorption\",               # Absorption\n",
    "    \"ft_act_site\",              # Active site\n",
    "    \"ft_binding\",               # Binding site\n",
    "    \"cc_catalytic_activity\",    # Catalytic activity\n",
    "    \"cc_cofactor\",              # Cofactor\n",
    "    \"ft_dna_bind\",              # DNA binding\n",
    "    \"cc_activity_regulation\",   # Activity regulation\n",
    "    \"cc_function\",              # Function [CC]\n",
    "    \"kinetics\",                 # Kinetics\n",
    "    \"cc_pathway\",               # Pathway\n",
    "    \"ph_dependence\",            # pH dependence\n",
    "    \"ft_site\",                  # Site\n",
    "    \"temp_dependence\",          # Temperature dependence\n",
    "    \"reviewed\",                 # Reviewed\n",
    "    \"go_p\",                     # GO (biological process)\n",
    "    \"go_c\",                     # GO (cellular component)\n",
    "    \"go\",                       # Gene Ontology (GO)\n",
    "    \"go_f\",                     # GO (molecular function)\n",
    "    \"go_id\",                    # Gene Ontology IDs\n",
    "    \"ft_mutagen\",               # Mutagenesis (Lab mutations)\n",
    "    \"ft_variant\",               # Natural variant (Crucial for disease/evolution)\n",
    "    \"cc_subcellular_location\",  # Subcellular location [CC]\n",
    "    \"structure_3d\",             # 3D\n",
    "    \"protein_families\",         # Protein families\n",
    "    \"cc_similarity\",            # Sequence similarities\n",
    "    \"xref_alphafolddb\"          # AlphaFoldDB\n",
    "]\n",
    "\n",
    "API_URL = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "\n",
    "# ==========================================\n",
    "# DOWNLOAD FUNCTION\n",
    "# ==========================================\n",
    "def download_data(name, config):\n",
    "    filename = f\"{name}.csv\"\n",
    "    print(f\"\\n[START] Collecting {name}...\")\n",
    "    print(f\"Query: {config['query']}\")\n",
    "    \n",
    "    # UniProt requires a User-Agent header with an email\n",
    "    headers = {\n",
    "        \"User-Agent\": f\"PythonScript/1.0 ({CONTACT_EMAIL})\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"query\": config[\"query\"],\n",
    "        \"format\": \"tsv\",     # TSV is safer to stream\n",
    "        \"fields\": \",\".join(fields)\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    try:\n",
    "        # stream=True is essential for large datasets\n",
    "        with requests.get(API_URL, params=params, headers=headers, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # iter_lines yields byte strings, we decode them\n",
    "            lines = response.iter_lines(decode_unicode=True)\n",
    "            \n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                # Write Header\n",
    "                try:\n",
    "                    header = next(lines).split(\"\\t\")\n",
    "                    writer.writerow(header)\n",
    "                except StopIteration:\n",
    "                    print(f\"[ERROR] No data found for {name}\")\n",
    "                    return\n",
    "\n",
    "                # Write Data\n",
    "                for line in lines:\n",
    "                    if line:\n",
    "                        writer.writerow(line.split(\"\\t\"))\n",
    "                        count += 1\n",
    "                        \n",
    "                        # Progress indicator (every 50k rows for speed)\n",
    "                        if count % 50000 == 0:\n",
    "                            sys.stdout.write(f\"\\rRows saved: {count}\")\n",
    "                            sys.stdout.flush()\n",
    "                            break\n",
    "                        \n",
    "                        if config[\"limit\"] and count >= config[\"limit\"]:\n",
    "                            print(f\"\\n[STOP] Reached limit of {config['limit']}\")\n",
    "                            break\n",
    "        \n",
    "        print(f\"\\n[DONE] Saved {count} rows to {filename}\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"\\n[ERROR] HTTP Error: {err}\")\n",
    "        if response.status_code == 403:\n",
    "            print(\"Hint: 403 usually means UniProt blocked the script. Check your CONTACT_EMAIL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Failed to download {name}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# RUN\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    for name, config in datasets.items():\n",
    "        download_data(name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b89d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[START] Collecting heat_extremethermoproteota...\n",
      "Query: (taxonomy_id:2281 OR taxonomy_id:2269 OR taxonomy_id:189538) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\n",
      "\n",
      "[DONE] Saved 2284 rows to heat_extremethermoproteota.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. User Identification (REQUIRED by UniProt to avoid 403 Errors)\n",
    "# Please replace with your actual email so UniProt can contact you if the script causes issues.\n",
    "CONTACT_EMAIL = \"uusshas12@gmail.com\"\n",
    "\n",
    "# 2. Define Datasets & Queries\n",
    "# Limits removed to collect ALL available data as requested.\n",
    "datasets = {\n",
    "    \"heat_extremethermoproteota\": {\n",
    "        \"query\": \"(taxonomy_id:2281 OR taxonomy_id:2269 OR taxonomy_id:189538) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\",\n",
    "        \"limit\": None    # Download all (~222k)\n",
    "    }\n",
    "#     \"salt_extreme_halobacteria\": {\n",
    "#         \"query\": \"(taxonomy_id:183963) AND (fragment:false) AND (length:[100 TO 800]) AND NOT (keyword:methanogen) AND (reviewed:false)\",\n",
    "#         \"limit\": None    # Download all (~1M)\n",
    "#     }\n",
    "}\n",
    "\n",
    "# 3. Define Columns (Mapped to UniProt API Fields)\n",
    "fields = [\n",
    "    \"id\",                       # Entry Name\n",
    "    \"gene_names\",               # Gene Names\n",
    "    \"organism_name\",            # Organism\n",
    "    \"organism_id\",              # Organism (ID)\n",
    "    \"protein_name\",             # Protein names\n",
    "    \"xref_proteomes\",           # Proteomes (Group by this later)\n",
    "    \"fragment\",                 # Fragment\n",
    "    \"length\",                   # Length\n",
    "    \"sequence\",                 # Sequence\n",
    "    \"absorption\",               # Absorption\n",
    "    \"ft_act_site\",              # Active site\n",
    "    \"ft_binding\",               # Binding site\n",
    "    \"cc_catalytic_activity\",    # Catalytic activity\n",
    "    \"cc_cofactor\",              # Cofactor\n",
    "    \"ft_dna_bind\",              # DNA binding\n",
    "    \"cc_activity_regulation\",   # Activity regulation\n",
    "    \"cc_function\",              # Function [CC]\n",
    "    \"kinetics\",                 # Kinetics\n",
    "    \"cc_pathway\",               # Pathway\n",
    "    \"ph_dependence\",            # pH dependence\n",
    "    \"ft_site\",                  # Site\n",
    "    \"temp_dependence\",          # Temperature dependence\n",
    "    \"reviewed\",                 # Reviewed\n",
    "    \"go_p\",                     # GO (biological process)\n",
    "    \"go_c\",                     # GO (cellular component)\n",
    "    \"go\",                       # Gene Ontology (GO)\n",
    "    \"go_f\",                     # GO (molecular function)\n",
    "    \"go_id\",                    # Gene Ontology IDs\n",
    "    \"ft_mutagen\",               # Mutagenesis (Lab mutations)\n",
    "    \"ft_variant\",               # Natural variant (Crucial for disease/evolution)\n",
    "    \"cc_subcellular_location\",  # Subcellular location [CC]\n",
    "    \"structure_3d\",             # 3D\n",
    "    \"protein_families\",         # Protein families\n",
    "    \"cc_similarity\",            # Sequence similarities\n",
    "    \"xref_alphafolddb\"          # AlphaFoldDB\n",
    "]\n",
    "\n",
    "API_URL = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "\n",
    "# ==========================================\n",
    "# DOWNLOAD FUNCTION\n",
    "# ==========================================\n",
    "def download_data(name, config):\n",
    "    filename = f\"{name}.csv\"\n",
    "    print(f\"\\n[START] Collecting {name}...\")\n",
    "    print(f\"Query: {config['query']}\")\n",
    "    \n",
    "    # UniProt requires a User-Agent header with an email\n",
    "    headers = {\n",
    "        \"User-Agent\": f\"PythonScript/1.0 ({CONTACT_EMAIL})\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"query\": config[\"query\"],\n",
    "        \"format\": \"tsv\",     # TSV is safer to stream\n",
    "        \"fields\": \",\".join(fields)\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    try:\n",
    "        # stream=True is essential for large datasets\n",
    "        with requests.get(API_URL, params=params, headers=headers, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # iter_lines yields byte strings, we decode them\n",
    "            lines = response.iter_lines(decode_unicode=True)\n",
    "            \n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                # Write Header\n",
    "                try:\n",
    "                    header = next(lines).split(\"\\t\")\n",
    "                    writer.writerow(header)\n",
    "                except StopIteration:\n",
    "                    print(f\"[ERROR] No data found for {name}\")\n",
    "                    return\n",
    "\n",
    "                # Write Data\n",
    "                for line in lines:\n",
    "                    if line:\n",
    "                        writer.writerow(line.split(\"\\t\"))\n",
    "                        count += 1\n",
    "                        \n",
    "                        # Progress indicator (every 50k rows for speed)\n",
    "                        if count % 50000 == 0:\n",
    "                            sys.stdout.write(f\"\\rRows saved: {count}\")\n",
    "                            sys.stdout.flush()\n",
    "                            break\n",
    "                        \n",
    "                        if config[\"limit\"] and count >= config[\"limit\"]:\n",
    "                            print(f\"\\n[STOP] Reached limit of {config['limit']}\")\n",
    "                            break\n",
    "        \n",
    "        print(f\"\\n[DONE] Saved {count} rows to {filename}\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"\\n[ERROR] HTTP Error: {err}\")\n",
    "        if response.status_code == 403:\n",
    "            print(\"Hint: 403 usually means UniProt blocked the script. Check your CONTACT_EMAIL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Failed to download {name}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# RUN\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    for name, config in datasets.items():\n",
    "        download_data(name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0d51f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[START] Collecting control_mesophilic...\n",
      "Query: (taxonomy_id:1236) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\n",
      "Rows saved: 50000\n",
      "[DONE] Saved 50000 rows to control_mesophilic.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. User Identification (REQUIRED by UniProt to avoid 403 Errors)\n",
    "# Please replace with your actual email so UniProt can contact you if the script causes issues.\n",
    "CONTACT_EMAIL = \"uusshas12@gmail.com\"\n",
    "\n",
    "# 2. Define Datasets & Queries\n",
    "# Limits removed to collect ALL available data as requested.\n",
    "datasets = {\n",
    "    \"control_mesophilic\": {\n",
    "        \"query\": \"(taxonomy_id:1236) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\",\n",
    "        \"limit\": None    # Download all (~222k)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Define Columns (Mapped to UniProt API Fields)\n",
    "fields = [\n",
    "    \"id\",                       # Entry Name\n",
    "    \"gene_names\",               # Gene Names\n",
    "    \"organism_name\",            # Organism\n",
    "    \"organism_id\",              # Organism (ID)\n",
    "    \"protein_name\",             # Protein names\n",
    "    \"xref_proteomes\",           # Proteomes (Group by this later)\n",
    "    \"fragment\",                 # Fragment\n",
    "    \"length\",                   # Length\n",
    "    \"sequence\",                 # Sequence\n",
    "    \"absorption\",               # Absorption\n",
    "    \"ft_act_site\",              # Active site\n",
    "    \"ft_binding\",               # Binding site\n",
    "    \"cc_catalytic_activity\",    # Catalytic activity\n",
    "    \"cc_cofactor\",              # Cofactor\n",
    "    \"ft_dna_bind\",              # DNA binding\n",
    "    \"cc_activity_regulation\",   # Activity regulation\n",
    "    \"cc_function\",              # Function [CC]\n",
    "    \"kinetics\",                 # Kinetics\n",
    "    \"cc_pathway\",               # Pathway\n",
    "    \"ph_dependence\",            # pH dependence\n",
    "    \"ft_site\",                  # Site\n",
    "    \"temp_dependence\",          # Temperature dependence\n",
    "    \"reviewed\",                 # Reviewed\n",
    "    \"go_p\",                     # GO (biological process)\n",
    "    \"go_c\",                     # GO (cellular component)\n",
    "    \"go\",                       # Gene Ontology (GO)\n",
    "    \"go_f\",                     # GO (molecular function)\n",
    "    \"go_id\",                    # Gene Ontology IDs\n",
    "    \"ft_mutagen\",               # Mutagenesis (Lab mutations)\n",
    "    \"ft_variant\",               # Natural variant (Crucial for disease/evolution)\n",
    "    \"cc_subcellular_location\",  # Subcellular location [CC]\n",
    "    \"structure_3d\",             # 3D\n",
    "    \"protein_families\",         # Protein families\n",
    "    \"cc_similarity\",            # Sequence similarities\n",
    "    \"xref_alphafolddb\"          # AlphaFoldDB\n",
    "]\n",
    "\n",
    "API_URL = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "\n",
    "# ==========================================\n",
    "# DOWNLOAD FUNCTION\n",
    "# ==========================================\n",
    "def download_data(name, config):\n",
    "    filename = f\"{name}.csv\"\n",
    "    print(f\"\\n[START] Collecting {name}...\")\n",
    "    print(f\"Query: {config['query']}\")\n",
    "    \n",
    "    # UniProt requires a User-Agent header with an email\n",
    "    headers = {\n",
    "        \"User-Agent\": f\"PythonScript/1.0 ({CONTACT_EMAIL})\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"query\": config[\"query\"],\n",
    "        \"format\": \"tsv\",     # TSV is safer to stream\n",
    "        \"fields\": \",\".join(fields)\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    try:\n",
    "        # stream=True is essential for large datasets\n",
    "        with requests.get(API_URL, params=params, headers=headers, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # iter_lines yields byte strings, we decode them\n",
    "            lines = response.iter_lines(decode_unicode=True)\n",
    "            \n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                # Write Header\n",
    "                try:\n",
    "                    header = next(lines).split(\"\\t\")\n",
    "                    writer.writerow(header)\n",
    "                except StopIteration:\n",
    "                    print(f\"[ERROR] No data found for {name}\")\n",
    "                    return\n",
    "\n",
    "                # Write Data\n",
    "                for line in lines:\n",
    "                    if line:\n",
    "                        writer.writerow(line.split(\"\\t\"))\n",
    "                        count += 1\n",
    "                        \n",
    "                        # Progress indicator (every 50k rows for speed)\n",
    "                        if count % 50000 == 0:\n",
    "                            sys.stdout.write(f\"\\rRows saved: {count}\")\n",
    "                            sys.stdout.flush()\n",
    "                            break\n",
    "                        \n",
    "                        if config[\"limit\"] and count >= config[\"limit\"]:\n",
    "                            print(f\"\\n[STOP] Reached limit of {config['limit']}\")\n",
    "                            break\n",
    "        \n",
    "        print(f\"\\n[DONE] Saved {count} rows to {filename}\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"\\n[ERROR] HTTP Error: {err}\")\n",
    "        if response.status_code == 403:\n",
    "            print(\"Hint: 403 usually means UniProt blocked the script. Check your CONTACT_EMAIL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Failed to download {name}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# RUN\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    for name, config in datasets.items():\n",
    "        download_data(name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6134759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[START] Collecting control_mesophilic_archaea...\n",
      "Query: (taxonomy_id:183925) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\n",
      "\n",
      "[DONE] Saved 1114 rows to control_mesophilic_archaea.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. User Identification (REQUIRED by UniProt to avoid 403 Errors)\n",
    "# Please replace with your actual email so UniProt can contact you if the script causes issues.\n",
    "CONTACT_EMAIL = \"uusshas12@gmail.com\"\n",
    "\n",
    "# 2. Define Datasets & Queries\n",
    "# Limits removed to collect ALL available data as requested.\n",
    "datasets = {\n",
    "    \"control_mesophilic_archaea\": {\n",
    "        \"query\": \"(taxonomy_id:183925) AND (fragment:false) AND (length:[100 TO 800]) AND (reviewed:true)\",\n",
    "        \"limit\": None    # Download all (~222k)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Define Columns (Mapped to UniProt API Fields)\n",
    "fields = [\n",
    "    \"id\",                       # Entry Name\n",
    "    \"gene_names\",               # Gene Names\n",
    "    \"organism_name\",            # Organism\n",
    "    \"organism_id\",              # Organism (ID)\n",
    "    \"protein_name\",             # Protein names\n",
    "    \"xref_proteomes\",           # Proteomes (Group by this later)\n",
    "    \"fragment\",                 # Fragment\n",
    "    \"length\",                   # Length\n",
    "    \"sequence\",                 # Sequence\n",
    "    \"absorption\",               # Absorption\n",
    "    \"ft_act_site\",              # Active site\n",
    "    \"ft_binding\",               # Binding site\n",
    "    \"cc_catalytic_activity\",    # Catalytic activity\n",
    "    \"cc_cofactor\",              # Cofactor\n",
    "    \"ft_dna_bind\",              # DNA binding\n",
    "    \"cc_activity_regulation\",   # Activity regulation\n",
    "    \"cc_function\",              # Function [CC]\n",
    "    \"kinetics\",                 # Kinetics\n",
    "    \"cc_pathway\",               # Pathway\n",
    "    \"ph_dependence\",            # pH dependence\n",
    "    \"ft_site\",                  # Site\n",
    "    \"temp_dependence\",          # Temperature dependence\n",
    "    \"reviewed\",                 # Reviewed\n",
    "    \"go_p\",                     # GO (biological process)\n",
    "    \"go_c\",                     # GO (cellular component)\n",
    "    \"go\",                       # Gene Ontology (GO)\n",
    "    \"go_f\",                     # GO (molecular function)\n",
    "    \"go_id\",                    # Gene Ontology IDs\n",
    "    \"ft_mutagen\",               # Mutagenesis (Lab mutations)\n",
    "    \"ft_variant\",               # Natural variant (Crucial for disease/evolution)\n",
    "    \"cc_subcellular_location\",  # Subcellular location [CC]\n",
    "    \"structure_3d\",             # 3D\n",
    "    \"protein_families\",         # Protein families\n",
    "    \"cc_similarity\",            # Sequence similarities\n",
    "    \"xref_alphafolddb\"          # AlphaFoldDB\n",
    "]\n",
    "\n",
    "API_URL = \"https://rest.uniprot.org/uniprotkb/stream\"\n",
    "\n",
    "# ==========================================\n",
    "# DOWNLOAD FUNCTION\n",
    "# ==========================================\n",
    "def download_data(name, config):\n",
    "    filename = f\"{name}.csv\"\n",
    "    print(f\"\\n[START] Collecting {name}...\")\n",
    "    print(f\"Query: {config['query']}\")\n",
    "    \n",
    "    # UniProt requires a User-Agent header with an email\n",
    "    headers = {\n",
    "        \"User-Agent\": f\"PythonScript/1.0 ({CONTACT_EMAIL})\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"query\": config[\"query\"],\n",
    "        \"format\": \"tsv\",     # TSV is safer to stream\n",
    "        \"fields\": \",\".join(fields)\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    try:\n",
    "        # stream=True is essential for large datasets\n",
    "        with requests.get(API_URL, params=params, headers=headers, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # iter_lines yields byte strings, we decode them\n",
    "            lines = response.iter_lines(decode_unicode=True)\n",
    "            \n",
    "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                \n",
    "                # Write Header\n",
    "                try:\n",
    "                    header = next(lines).split(\"\\t\")\n",
    "                    writer.writerow(header)\n",
    "                except StopIteration:\n",
    "                    print(f\"[ERROR] No data found for {name}\")\n",
    "                    return\n",
    "\n",
    "                # Write Data\n",
    "                for line in lines:\n",
    "                    if line:\n",
    "                        writer.writerow(line.split(\"\\t\"))\n",
    "                        count += 1\n",
    "                        \n",
    "                        # Progress indicator (every 50k rows for speed)\n",
    "                        if count % 50000 == 0:\n",
    "                            sys.stdout.write(f\"\\rRows saved: {count}\")\n",
    "                            sys.stdout.flush()\n",
    "                            break\n",
    "                        \n",
    "                        if config[\"limit\"] and count >= config[\"limit\"]:\n",
    "                            print(f\"\\n[STOP] Reached limit of {config['limit']}\")\n",
    "                            break\n",
    "        \n",
    "        print(f\"\\n[DONE] Saved {count} rows to {filename}\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"\\n[ERROR] HTTP Error: {err}\")\n",
    "        if response.status_code == 403:\n",
    "            print(\"Hint: 403 usually means UniProt blocked the script. Check your CONTACT_EMAIL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] Failed to download {name}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# RUN\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    for name, config in datasets.items():\n",
    "        download_data(name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679fa1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
